{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import threading\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "\n",
    "# input: file name\n",
    "# output: object with vertex keys and their head vertices\n",
    "def preprocess_adj_list(filename):\n",
    "    graph_obj = {}\n",
    "    with open(filename) as f_handle:\n",
    "        for line in f_handle:\n",
    "            u, v = line.split()\n",
    "            u = int(u)\n",
    "            v = int(v)\n",
    "            graph_obj.setdefault(u, []).append(v)\n",
    "\n",
    "            # dont forget nodes with no outgoing arcs\n",
    "            if v not in graph_obj:\n",
    "                graph_obj.setdefault(v, [])\n",
    "\n",
    "    return graph_obj\n",
    "\n",
    "\n",
    "# input: object with vertex keys and their head vertices\n",
    "# output: Graph instantiated with input graph object\n",
    "def create_graph(graph_obj):\n",
    "    G = Graph()\n",
    "    for v_key in graph_obj:\n",
    "        v = Vertex(v_key) if v_key not in G else G.get_v(v_key)\n",
    "        for head_key in graph_obj[v_key]:\n",
    "            # v gets a tail_of value of head_key (useful for normal graph traversal)\n",
    "            v.add_head(head_key)\n",
    "\n",
    "            # v_head gets a head_of value of v_key (useful for traversing graph backwards)\n",
    "            v_head = Vertex(head_key) if head_key not in G else G.get_v(head_key)\n",
    "            v_head.add_tail(v_key)\n",
    "            G.add_v(v_head)\n",
    "\n",
    "        G.add_v(v)\n",
    "    return G\n",
    "\n",
    "\n",
    "# Vertex class for directed graphs (object with 'key', 'tail_of', and 'head_of' keys)\n",
    "class Vertex():\n",
    "    def __init__(self, key):\n",
    "        self._key = key\n",
    "        self._tail_of = {}\n",
    "        self._head_of = {}\n",
    "\n",
    "    def __str__(self):\n",
    "        return '{' + \"'key': {}, 'tail_of': {}, 'head_of': {}\".format(\n",
    "            self._key,\n",
    "            self._tail_of,\n",
    "            self._head_of\n",
    "        ) + '}'\n",
    "\n",
    "    def add_head(self, head_key, weight=1):\n",
    "        if (head_key):\n",
    "            self._tail_of[head_key] = weight\n",
    "\n",
    "    def add_tail(self, tail_key, weight=1):\n",
    "        if (tail_key):\n",
    "            self._head_of[tail_key] = weight\n",
    "\n",
    "    def tail_of(self, head_key):\n",
    "        return head_key in self._tail_of\n",
    "\n",
    "    def head_of(self, tail_key):\n",
    "        return tail_key in self._head_of\n",
    "\n",
    "    def get_tail_of_keys(self):\n",
    "        return list(self._tail_of.keys())\n",
    "\n",
    "    def get_head_of_keys(self):\n",
    "        return list(self._head_of.keys())\n",
    "\n",
    "    def remove_tail(self, tail_key):\n",
    "        if tail_key in self._head_of:\n",
    "            del self._head_of[tail_key]\n",
    "\n",
    "    def remove_head(self, head_key):\n",
    "        if head_key in self._tail_of:\n",
    "            del self._tail_of[head_key]\n",
    "\n",
    "    def get_tail_weight(self, tail_key):\n",
    "        if tail_key in self._head_of:\n",
    "            return self._head_of[tail_key]\n",
    "\n",
    "    def get_head_weight(self, head_key):\n",
    "        if head_key in self._tail_of:\n",
    "            return self._tail_of[head_key]\n",
    "\n",
    "\n",
    "# Directed graph class\n",
    "class Graph():\n",
    "    def __init__(self):\n",
    "        self._vertices = {}\n",
    "\n",
    "    # 'x in graph' will use this containment logic\n",
    "    def __contains__(self, key):\n",
    "        return key in self._vertices\n",
    "\n",
    "    # 'for x in graph' will use this iter() definition, where x is a vertex in an array\n",
    "    def __iter__(self):\n",
    "        return iter(self._vertices.values())\n",
    "\n",
    "    def __str__(self):\n",
    "        output = '\\n{\\n'\n",
    "        vertices = self._vertices.values()\n",
    "        for v in vertices:\n",
    "            graph_key = \"{}\".format(v._key)\n",
    "            v_str = \"\\n   'key': {}, \\n   'tail_of': {}, \\n   'head_of': {}\".format(\n",
    "                v._key,\n",
    "                v._tail_of,\n",
    "                v._head_of\n",
    "            )\n",
    "            output += ' ' + graph_key + ': {' + v_str + '\\n },\\n'\n",
    "        return output + '}'\n",
    "\n",
    "    def add_v(self, v):\n",
    "        if v:\n",
    "            self._vertices[v._key] = v\n",
    "        return self\n",
    "\n",
    "    def get_v(self, key):\n",
    "        try:\n",
    "            return self._vertices[key]\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "    def get_v_keys(self):\n",
    "        return list(self._vertices.keys())\n",
    "\n",
    "    # removes vertex as head and tail from all its neighbors, then deletes vertex\n",
    "    def remove_v(self, key):\n",
    "        if key in self._vertices:\n",
    "            head_of_keys = self._vertices[key].get_head_of_keys()\n",
    "            tail_of_keys = self._vertices[key].get_tail_of_keys()\n",
    "            for tail_key in head_of_keys:\n",
    "                self.remove_head(tail_key, key)\n",
    "            for head_key in tail_of_keys:\n",
    "                self.remove_tail(key, head_key)\n",
    "            del self._vertices[key]\n",
    "\n",
    "    def add_e(self, tail_key, head_key, weight=1):\n",
    "        if tail_key not in self._vertices:\n",
    "            self.add_v(Vertex(tail_key))\n",
    "        if head_key not in self._vertices:\n",
    "            self.add_v(Vertex(head_key))\n",
    "\n",
    "        self._vertices[tail_key].add_head(head_key, weight)\n",
    "\n",
    "    def get_e(self, tail_key, head_key):\n",
    "        if tail_key and head_key in self._vertices:\n",
    "            return self.get_v(tail_key).get_e(head_key)\n",
    "\n",
    "    # adds the weight for an edge if it exists already, with a default of 1\n",
    "    def increase_e(self, tail_key, head_key, weight=1):\n",
    "        if tail_key not in self._vertices:\n",
    "            self.add_v(Vertex(tail_key))\n",
    "        if head_key not in self._vertices:\n",
    "            self.add_v(Vertex(head_key))\n",
    "\n",
    "        w_v1_v2 = self.get_v(tail_key).get_head_weight(head_key)\n",
    "        new_w_v1_v2 = w_v1_v2 + weight if w_v1_v2 else weight\n",
    "\n",
    "        self._vertices[tail_key].add_head(head_key, new_w_v1_v2)\n",
    "\n",
    "    def has_forward_e(self, tail_key, head_key):\n",
    "        if tail_key in self._vertices:\n",
    "            return self._vertices[tail_key].tail_of(head_key)\n",
    "\n",
    "    def remove_tail(self, tail_key, head_key):\n",
    "        if head_key in self._vertices:\n",
    "            self._vertices[head_key].remove_tail(tail_key)\n",
    "\n",
    "    def remove_head(self, tail_key, head_key):\n",
    "        if tail_key in self._vertices:\n",
    "            self._vertices[tail_key].remove_head(head_key)\n",
    "\n",
    "    def remove_e(self, tail_key, head_key):\n",
    "        if tail_key in self._vertices:\n",
    "            self._vertices[tail_key].remove_head(head_key)\n",
    "        if head_key in self._vertices:\n",
    "            self._vertices[head_key].remove_tail(tail_key)\n",
    "\n",
    "    def for_each_v(self, cb):\n",
    "        for v in self._vertices:\n",
    "            cb(v)\n",
    "\n",
    "\n",
    "# Global variables\n",
    "EXPLORED = {}\n",
    "# 1st DFS loop\n",
    "t = 0  # increment when a node and its children have been fully explored\n",
    "F = []  # tracks node finishing times (e.g. [x,y,z] for 3 nodes labeled 1, 2, and 3)\n",
    "\n",
    "# 2nd DFS loop\n",
    "Q = []  # append a node before DFS_G subroutine is called from it\n",
    "LEADERS = {}  # tracks node \"leaders\", i.e. node DFS_G was called from to discover them\n",
    "\n",
    "\n",
    "# input: Graph, vertex key, iteration of DFS loop (1st or 2nd)\n",
    "def DFS_rec(G, v_key, loop):\n",
    "    global t, F, EXPLORED\n",
    "    EXPLORED[v_key] = 1\n",
    "\n",
    "    # Leader of a vertex is its DFS_G subroutine source vertex\n",
    "    if loop == 2:\n",
    "        LEADERS[v_key] = Q[-1]\n",
    "\n",
    "    v = G.get_v(v_key)\n",
    "    v_heads = v.get_tail_of_keys() if loop == 2 else v.get_head_of_keys()\n",
    "    for v_head in v_heads:\n",
    "        if v_head not in EXPLORED:\n",
    "            DFS_rec(G, v_head, loop)\n",
    "\n",
    "    # When v_key has no more outgoing arcs, t++ and record t as its finishing time\n",
    "    if loop == 1:\n",
    "        t += 1\n",
    "        F[v_key - 1] = t  # assumes node labels are integers 1-n\n",
    "\n",
    "\n",
    "# input: Graph, order of iteration for keys, iteration of DFS loop (1st or 2nd)\n",
    "def DFS_iterative(G, sorted_keys, loop):\n",
    "    global t, F, Q, EXPLORED\n",
    "\n",
    "    for key in sorted_keys:\n",
    "        Q.append(key)  # appends each key to an always-empty Q\n",
    "\n",
    "        while (Q):  # Q empties for each new leader vertex, being populated with another key above\n",
    "            v_key = Q.pop(0)  # removes the front key from Q as we deal with it\n",
    "\n",
    "            if v_key not in EXPLORED:\n",
    "                # adds that key back to beginning of Q if first time seen, but now marks\n",
    "                # it as explored (so next time we see it, after exploring all its children,\n",
    "                # we can record its finishing time)\n",
    "                Q = [v_key] + Q\n",
    "                EXPLORED[v_key] = 1\n",
    "                if loop == 2:\n",
    "                    LEADERS[v_key] = Q[-1]  # leader always at Q end; new leaders added to empty Q\n",
    "\n",
    "                v = G.get_v(v_key)\n",
    "                v_heads = v.get_head_of_keys() if loop == 1 else v.get_tail_of_keys()\n",
    "                for w in v_heads:\n",
    "                    if w not in EXPLORED:\n",
    "                        Q = [w] + Q  # adds all children to beginning of Q if never seen\n",
    "\n",
    "            else:\n",
    "                v_fin_time = F[v_key - 1]\n",
    "                if v_fin_time is None:\n",
    "                    t += 1\n",
    "                    v_fin_time = t\n",
    "\n",
    "\n",
    "# input: Graph, iteration of DFS loop (1 or 2)\n",
    "def DFS_loop(G, loop):\n",
    "    global F, Q, EXPLORED\n",
    "    EXPLORED = {}\n",
    "\n",
    "    if loop == 1:\n",
    "        keys = G.get_v_keys()\n",
    "        sorted_keys = list(reversed(keys))\n",
    "        F = [None] * len(keys)\n",
    "    else:\n",
    "        # Sorts nodes in reverse topological order, i.e. descending order of finishing times\n",
    "        # i = [b[0] for b in sorted(enumerate(F), key=lambda i:i[1], reverse=True)]\n",
    "        i = sorted(range(len(F)), key=lambda k: F[k], reverse=True)\n",
    "        sorted_keys = [x + 1 for x in i]\n",
    "        # print('reverse toplogical order: ', sorted_keys)\n",
    "\n",
    "    # Solution with recursive DFS\n",
    "    for v_key in sorted_keys:\n",
    "        if v_key not in EXPLORED:\n",
    "            if loop == 2:\n",
    "                Q.append(v_key)\n",
    "            DFS_rec(G, v_key, loop)\n",
    "\n",
    "    # Solution with iterative DFS\n",
    "    # DFS_iterative(G, sorted_keys, loop)\n",
    "\n",
    "\n",
    "# input: Graph and number of SCC sizes to return\n",
    "# output: size of 5 largest SCCs\n",
    "def strongly_connected_components(G, num):\n",
    "    # 1) Run DFS traversing arcs backwards to gather searched finishing times of nodes in F\n",
    "    DFS_loop(G, 1)\n",
    "    # print('F: ', F)\n",
    "    # print('t: ', t)\n",
    "\n",
    "    # 1b) Now that we have finishing times of first DFS, run DFS loop on G vertices in\n",
    "    # descending order of these times. This will allow us to find only 1 SCC at a time (marking\n",
    "    # as 'explored' nodes in 1 SCC so we don't explore their children again), potentially\n",
    "    # even starting with sink vertices which have no outgoing arcs and are thus their own SCC.\n",
    "\n",
    "    # 2) Run DFS loop on G vertex keys in descending order of finishing times\n",
    "    DFS_loop(G, 2)\n",
    "    # print('LEADERS: ', LEADERS)\n",
    "    return find_largest(num)\n",
    "\n",
    "\n",
    "# Uses global 'leaders' object with vertex keys and their leader\n",
    "# input: number of SCC sizes to return\n",
    "# output: SCC sizes\n",
    "def find_largest(num):\n",
    "    SCCs = {}  # leader keys and their SCC size\n",
    "    for v in LEADERS:\n",
    "        leader = LEADERS[v]\n",
    "        SCCs[leader] = SCCs.get(leader, 0) + 1\n",
    "    # print('SCCs: ', SCCs)\n",
    "\n",
    "    sizes = sorted(SCCs.values(), reverse=True)[:num]\n",
    "    return sizes + ([0] * (num - len(sizes)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    graph_obj = preprocess_adj_list('SCC.txt')\n",
    "    # pprint.pprint(graph_obj, width=40)\n",
    "    graph = create_graph(graph_obj)\n",
    "    print(graph)\n",
    "\n",
    "    sys.setrecursionlimit(800000)\n",
    "    threading.stack_size(67108864)\n",
    "\n",
    "    start = time.time()\n",
    "    result = strongly_connected_components(graph, 5)\n",
    "    print(result)\n",
    "    print('elapsed time: ', time.time() - start)\n",
    "\n",
    "\n",
    "thread = threading.Thread(target=main)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "098a54a4cecd56946e77a7b5b29fc026a7f582aea2a2870f7c15ee99869650c5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
